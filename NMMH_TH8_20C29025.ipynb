{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j411dkkAuSvt"
   },
   "source": [
    "**Lab-08: Backpropagation**\n",
    "\n",
    "Trong b√†i th·ª±c h√†nh n√†y ch√∫ng ta s·∫Ω th·ª≠ c√†i ƒë·∫∑t Backpropagation \n",
    "\n",
    "Ta mu·ªën d·ª±a v√†o 2 chi·ªÅu c·ªßa l√°, ph√¢n bi·ªát gi·ªØa lo·∫°i l√° 1 v√† lo·∫°i l√° 2. C·ª• th·ªÉ, v·ªõi $x = (x_1,x_2, 1)$ l√† input, ta mu·ªën ƒëo√°n m·ªôt ph√¢n ph·ªëi\n",
    "    $$ P_\\\\theta(c|x),c = 0, 1 $$\n",
    "v·ªõi $\\\\theta$ l√† c√°c tham s·ªë\n",
    "Ta m√¥ h√¨nh $P_\\theta$ l√† m·ªôt neural network c√≥ 2 l·ªõp ·∫©n, m·ªói l·ªõp 5 neurons, t·ª©c l√†\\n\",\n",
    "    $$ P_\\\\theta(c|x) = \\\\text{softmax}(\\\\max(0, \\\\max(0, x \\\\cdot W_1 + b_1) \\\\cdot W_2 + b_2) \\\\cdot W_3 + b_3 )$$\n",
    "\n",
    "v·ªõi $x$ l√† vector d√≤ng $[[x_1, x_2]]$ k√≠ch th∆∞·ªõc $ 1\\times 2$, $W_1, W_2, W_3$ l√† c√°c ma tr·∫≠n c√≥ k√≠ch th∆∞·ªõc $2 \\times 5, 5 \\times 5, 5 \\times 3$, v√† $b_1, b_2, b_3$ l√† c√°c ma tr·∫≠n k√≠ch th∆∞·ªõc $1 \\times 5, 1 \\times 5, 1 \\times 3$.\n",
    "\n",
    "Khi ƒë√≥ $P(c|x)$ l√† m·ªôt vector d√≤ng ƒë·ªô d√†i 3, xem nh∆∞ $P(c|x)= (P_1(c|x), P_2(c|x), P_3(c|x)) = (P(c=0|x), P(c=1|x), P(c=2|x))$\n",
    "B·ªô c√°c ma tr·∫≠n $\\\\theta = (W_1, W_2, W_3, b_1, b_2, b_3)$ ch√≠nh l√† tham s·ªë c·∫ßn t√¨m c·ªßa model. Gi·ªù c·∫ßn t√¨m $\\\\theta$ sao cho \n",
    "\n",
    "$$ L = \\frac{1}{N} \\sum_{x,y} - y_0 \\log P_\\theta(0|x) -  y_1 \\log P_\\theta(1|x) - y_2 \\log P_\\theta(2|x) $$\n",
    "\n",
    "ƒë·∫°t gi√° tr·ªã nh·ªè nh·∫•t v·ªõi $y = (y_0, y_1, y_2)$ l√† one-hot vector bi·ªÉu th·ªã lo·∫°i l√° t∆∞∆°ng ·ª©ng v·ªõi $x$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hRjcNaFBigAx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zS_ADnTigA3"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DzecGvNIigA4"
   },
   "outputs": [],
   "source": [
    "def one_hot_vector(y):\n",
    "    out = np.zeros((y.shape[0], max(y)+1))\n",
    "    for i in range(y.shape[0]):\n",
    "        out[i, y[i]] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NpL3fpASigA5"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"https://raw.githubusercontent.com/huynhthanh98/ML/master/lab-08/bt_train.csv\")\n",
    "valid = pd.read_csv(\"https://raw.githubusercontent.com/huynhthanh98/ML/master/lab-08/bt_valid.csv\")\n",
    "\n",
    "x1_train = train[\"x1\"].values\n",
    "x2_train = train[\"x2\"].values\n",
    "y_train = train[\"label\"].values\n",
    "\n",
    "x1_valid = valid['x1'].values\n",
    "x2_valid = valid['x2'].values\n",
    "y_valid = valid['label'].values\n",
    "\n",
    "# normalize\n",
    "x1_mean = np.mean(x1_train)\n",
    "x1_std = np.std(x1_train)\n",
    "x2_mean = np.mean(x2_train)\n",
    "x2_std = np.std(x2_train)\n",
    "\n",
    "x1_train = (x1_train - x1_mean)/ x1_std\n",
    "x2_train = (x2_train - x2_mean)/ x2_std\n",
    "\n",
    "x1_valid = (x1_valid - x1_mean)/ x1_std\n",
    "x2_valid = (x2_valid - x2_mean)/ x2_std\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.concatenate([x1_train.reshape(-1,1), x2_train.reshape(-1,1)], axis=1)\n",
    "y_train = one_hot_vector(y_train)\n",
    "\n",
    "X_valid = np.concatenate([x1_valid.reshape(-1,1), x2_valid.reshape(-1,1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4_CidQJtigA7"
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "W1 = np.random.randn(2,5)\n",
    "W2 = np.random.randn(5,5)\n",
    "W3 = np.random.randn(5,3)\n",
    "\n",
    "b1 = np.random.randn(1,5)\n",
    "b2 = np.random.randn(1,5)\n",
    "b3 = np.random.randn(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Kw8mSDk6igA9"
   },
   "outputs": [],
   "source": [
    "def relu(h):\n",
    "    return np.array([max(0,i) for i in h.reshape(-1)]).reshape(h.shape)\n",
    "\n",
    "def softmax(z):\n",
    "      return np.exp(z)/ np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
    "\n",
    "def CrossEntropy(o,y):\n",
    "      return - np.sum(np.log(o)*y)\n",
    "\n",
    "ln = 0.001\n",
    "N = y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vjLI8EDoigA-"
   },
   "outputs": [],
   "source": [
    "for epochs in range(100000):\n",
    "    # foward\n",
    "    z1 = np.dot(X_train, W1) + b1\n",
    "    o1 = relu(z1)\n",
    "\n",
    "    z2 = np.dot(o1, W2) + b2\n",
    "    o2 = relu(z2)\n",
    "\n",
    "    z3 = np.dot(o2, W3) + b3\n",
    "    o3 = softmax(z3)\n",
    "\n",
    "    # backpropagation\n",
    "    dL_dz3 = 1/len(X_train)*(o3 - y_train) \n",
    "    dL_dW3 = np.dot(o2.T, dL_dz3)    \n",
    "    dL_db3 = np.sum(dL_dz3, axis = 0)\n",
    "\n",
    "\n",
    "    dL_do2 = np.dot(dL_dz3, W3.T)\n",
    "    dL_dz2 = dL_do2.copy()\n",
    "    dL_dz2[z2 < 0] = 0\n",
    "    dL_dW2 = np.dot(o1.T,dL_dz2)\n",
    "    dL_db2 = np.sum(dL_dz2, axis = 0)\n",
    "\n",
    "    dL_do1 = np.dot(dL_dz2, W2.T)\n",
    "    dL_dz1 = dL_do1.copy()\n",
    "    dL_dz1[z1 < 0] = 0\n",
    "    dL_dW1 = np.dot(X_train.T, dL_dz1)\n",
    "    dL_db1 = np.sum(dL_dz1, axis = 0)\n",
    "\n",
    "    W3 -= ln* dL_dW3\n",
    "    b3 -= ln* dL_db3\n",
    "    W2 -= ln* dL_dW2\n",
    "    b2 -= ln* dL_db2\n",
    "    W1 -= ln* dL_dW1\n",
    "    b1 -= ln* dL_db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DmSjKNZpigBA"
   },
   "outputs": [],
   "source": [
    "z1_valid = np.dot(X_valid, W1) + b1\n",
    "o1_valid = relu(z1_valid)\n",
    "\n",
    "z2_valid = np.dot(o1_valid, W2) + b2\n",
    "o2_valid = relu(z2_valid)\n",
    "\n",
    "z3_valid = np.dot(o2_valid, W3) + b3\n",
    "o3_valid = softmax(z3_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHthk1kuigBB",
    "outputId": "d3b0f643-fab9-472b-b78e-fbe99b1f3938"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6366666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(o3_valid, axis = 1) == y_valid)/ y_valid.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSZlBMhnewyH"
   },
   "source": [
    "#B√†i T·∫≠p\n",
    "1. T·ª´ code demo h√£y c√†i ƒë·∫∑t th√™m m·ªôt module ƒë·ªÉ ch·ªçn ra ƒë∆∞·ª£c b·ªô weights sao cho accuracy tr√™n t·∫≠p validation l√† t·ªët nh·∫•t.\n",
    "2. T·ª´ b·ªô d·ªØ li·ªáu b√™n d∆∞·ªõi h√£y c√†i ƒë·∫∑t backpropagation cho b√†i to√°n ph√¢n bi·ªát ung th∆∞ v√∫. H√£y t·ª± ch·ªçn s·ªë layers v√† s·ªë nodes m√† m√¨nh cho l√† th√≠ch h·ª£p, c≈©ng nh∆∞ l√† n√™u ra s·ªë layers v√† s·ªë nodes c·ªßa m·ªói layer m√† m√¨nh ƒë√£ ch·ªçn. T√≠nh accuracy tr√™n t·∫≠p training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ6ss-qM6nrK"
   },
   "source": [
    "C√¢u 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "W1 = np.random.randn(2,5)\n",
    "W2 = np.random.randn(5,5)\n",
    "W3 = np.random.randn(5,3)\n",
    "\n",
    "b1 = np.random.randn(1,5)\n",
    "b2 = np.random.randn(1,5)\n",
    "b3 = np.random.randn(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4x7T_rnj6i0B",
    "outputId": "83ccbb1a-61bd-4ef9-89b2-11d8108a16ad"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_valid_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2c59a9713fd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mvalid_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo3_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mvalid_accuracy\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_valid_accuracy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mmax_valid_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mepoch_opti\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_valid_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    #forward\n",
    "    z1 = np.dot(X_train, W1) + b1\n",
    "    o1 = relu(z1)\n",
    "    \n",
    "    z2 = np.dot(o1, W2) + b2\n",
    "    o2 = relu(z2)\n",
    "    \n",
    "    z3 = np.dot(o2, W3) + b3\n",
    "    o3 = softmax(z3)\n",
    "    \n",
    "    #backpropagation\n",
    "    dL_dz3 = 1/len(X_train)*(o3 - y_train)\n",
    "    dL_dW3 = np.dot(o2.T, dL_dz3)\n",
    "    dL_db3 = np.sum(dL_dz3, axis = 0)\n",
    "    \n",
    "    \n",
    "    dL_do2 = np.dot(dL_dz3, W3.T)\n",
    "    dL_dz2 = dL_do2.copy()\n",
    "    dL_dz2[z2 < 0] = 0\n",
    "    dL_db2 = np.sum(dL_dz2, axis = 0)\n",
    "    \n",
    "    dL_do1 = np.dot(dL_dz2, W2.T)\n",
    "    dL_dz1 = dL_do1.copy()\n",
    "    dL_dz1[z1 < 0] = 0\n",
    "    dL_dW1 = np.dot(X_train.T, dL_dz1)\n",
    "    dL_db1 = np.sum(dL_dz1, axis = 0)\n",
    "\n",
    "    W3 -= ln* dL_dW3\n",
    "    b3 -= ln* dL_db3\n",
    "    W2 -= ln* dL_dW2\n",
    "    b2 -= ln* dL_db2\n",
    "    W1 -= ln* dL_dW1\n",
    "    b1 -= ln* dL_db1\n",
    "\n",
    "    z1_valid = np.dot(X_valid, W1) + b1\n",
    "    o1_valid = relu(z1_valid)\n",
    "\n",
    "    z2_valid = np.dot(o1_valid, W2) + b2\n",
    "    o2_valid = relu(z2_valid)\n",
    "\n",
    "    z3_valid = np.dot(o2_valid, W3) + b3\n",
    "    o3_valid = softmax(z3_valid)\n",
    "\n",
    "    valid_accuracy = np.sum(np.argmax(o3_valid, axis = 1) == y_valid)/ y_valid.shape[0]\n",
    "\n",
    "    if valid_accuracy > max_valid_accuracy:\n",
    "        max_valid_accuracy = valid_accuracy\n",
    "        epoch_opti = epoch\n",
    "\n",
    "        W3_opti = W3\n",
    "        b3_opti = b3\n",
    "        W2_opti  = W2\n",
    "        b2_opti = b2\n",
    "        W1_opti  = W1\n",
    "        b1_opti = b1\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Accuracy in validation set at epoch {epoch} is {valid_accuracy:.4f}\")\n",
    "\n",
    "print(f\"Highest Accuracy in validation set obtained at epoch {epoch_opti} is {max_valid_accuracy:.4f}\")\n",
    "print(f\"Optimal weight are storaged in Wx_opti and bx_opti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta th·∫•y Accuracy cao nh·∫•t ƒë·∫°t ƒë∆∞·ª£c l√† ·ªü epoch cu·ªëi c√πng trong qu√° tr√¨nh train. \n",
    "Do ƒë√≥ c√≥ th·ªÉ th·∫•y l√† m√¥ h√¨nh c√≥ kh·∫£ nƒÉng cao l√† ch∆∞a b·ªã overfitting. C√≥ th·ªÉ tƒÉng s·ªë epoch train ƒë·ªÉ m√¥ h√¨nh h·ªôi t·ª• t·ªët h∆°n\n",
    "\n",
    "B·ªô parameter ùë°‚Ñéùëíùë°ùëé=(ùëä1,ùëä2,ùëä3,ùëè1,ùëè2,ùëè3) ƒë∆∞·ª£c l∆∞u l·∫°i khi m·ªói epoch train tr√™n t·∫≠p training set m√† c√≥ Accuracy tƒÉng so v·ªõi Accuracy cao nh·∫•t ƒë√£ ƒë·∫°t ƒë∆∞·ª£c tr∆∞·ªõc ƒë√≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAUX9Vdk6rh4"
   },
   "source": [
    "C√¢u 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NscLiyVYuPx"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "X = breast_cancer.data  \n",
    "y = breast_cancer.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_mean=np.mean(X_train)\n",
    "X_std=np.std(X_train)\n",
    "\n",
    "X_valid=(X_valid-X_mean)/X_std\n",
    "X_train=(X_train-X_mean)/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Crm2UvQi8Spi"
   },
   "outputs": [],
   "source": [
    "#S·ª≠ d·ª•ng one hot vector cho y_train ƒë·ªÉ t√≠nh Loss v·ªõi h√†m softmax ·ªü layer cu·ªëi\n",
    "y_train_1hot = one_hot_vector(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JC-cEdyg6wq4"
   },
   "outputs": [],
   "source": [
    "print(list(breast_cancer.feature_names))\n",
    "print(f'S·ªë l∆∞·ª£ng features input: {len(list(breast_cancer.feature_names))}')\n",
    "\n",
    "print(f'S·ªë l∆∞·ª£ng classes output: {len(list(np.unique(y)))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B·ªô d·ªØ li·ªáu v·ªÅ ung th∆∞ v√∫ c√≥ 30 features ·ª©ng v·ªõi 30 nodes input, 2 nodes output\n",
    "\n",
    "Ta thi·∫øt k·∫ø m·∫°ng Neuron v·ªõi 3 hidden layer v·ªõi s·ªë nodes l·∫ßn  l∆∞·ª£t l√† <br>\n",
    "L·ªõp 1: 15 node, L·ªõp 2: 15 node, L·ªõp 3: 5 node\n",
    "\n",
    "\n",
    "K√≠ch th∆∞·ªõc c√°c ma tr·∫≠n W1, W2, W3, W4 t∆∞∆°ng ·ª©ng l√†: 30x15, 15x15, 15x5, 5x2 <br>\n",
    "K√≠ch th∆∞·ªõc c√°c ma tr·∫≠n W1, W2, W3, W4 l√†: 1x15, 1x15, 1x5, 1x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FH7G3lx33R5A"
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "W1 = np.random.randn(30,15)\n",
    "W2 = np.random.randn(15,15)\n",
    "W3 = np.random.randn(15,5)\n",
    "W4 = np.random.randn(5,2)\n",
    "\n",
    "b1 = np.random.randn(1,15)\n",
    "b2 = np.random.randn(1,15)\n",
    "b3 = np.random.randn(1,5)\n",
    "b4 = np.random.randn(1,2)\n",
    "\n",
    "ln = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvlgt9kn3GVt"
   },
   "outputs": [],
   "source": [
    "max_valid_accuracy = 0\n",
    "\n",
    "for epoch in range(100000):\n",
    "    #foward\n",
    "    z1 = np.dot(X_train, W1) + b1\n",
    "    o1 = relu(z1)\n",
    "\n",
    "    z2 = np.dot(o1, W2) + b2\n",
    "    o2 = relu(z2)\n",
    "\n",
    "    z3 = np.dot(o2, W3) + b3\n",
    "    o3 = relu(z3)\n",
    "\n",
    "    z4 = np.dot(o3, W4) + b4\n",
    "    o4 = softmax(z4)\n",
    "\n",
    "    #backpropagation\n",
    "    dL_dz4 = 1/len(X_train)*(o4 - y_train_1hot) \n",
    "    dL_dW4 = np.dot(o3.T, dL_dz4)    \n",
    "    dL_db4 = np.sum(dL_dz4, axis = 0)\n",
    "\n",
    "    dL_do3 = np.dot(dL_dz4, W4.T)\n",
    "    dL_dz3 = dL_do3.copy()\n",
    "    dL_dz3[z3 < 0] = 0\n",
    "    dL_dW3 = np.dot(o2.T,dL_dz3)\n",
    "    dL_db3 = np.sum(dL_dz3, axis = 0)\n",
    "\n",
    "    dL_do2 = np.dot(dL_dz3, W3.T)\n",
    "    dL_dz2 = dL_do2.copy()\n",
    "    dL_dz2[z2 < 0] = 0\n",
    "    dL_dW2 = np.dot(o1.T,dL_dz2)\n",
    "    dL_db2 = np.sum(dL_dz2, axis = 0)\n",
    "\n",
    "    dL_do1 = np.dot(dL_dz2, W2.T)\n",
    "    dL_dz1 = dL_do1.copy()\n",
    "    dL_dz1[z1 < 0] = 0\n",
    "    dL_dW1 = np.dot(X_train.T, dL_dz1)\n",
    "    dL_db1 = np.sum(dL_dz1, axis = 0)\n",
    "\n",
    "    W4 -= ln* dL_dW4\n",
    "    b4 -= ln* dL_db4\n",
    "    W3 -= ln* dL_dW3\n",
    "    b3 -= ln* dL_db3\n",
    "    W2 -= ln* dL_dW2\n",
    "    b2 -= ln* dL_db2\n",
    "    W1 -= ln* dL_dW1\n",
    "    b1 -= ln* dL_db1\n",
    "\n",
    "    z1_valid = np.dot(X_valid, W1) + b1\n",
    "    o1_valid = relu(z1_valid)\n",
    "\n",
    "    z2_valid = np.dot(o1_valid, W2) + b2\n",
    "    o2_valid = relu(z2_valid)\n",
    "\n",
    "    z3_valid = np.dot(o2_valid, W3) + b3\n",
    "    o3_valid = softmax(z3_valid)\n",
    "\n",
    "    z4_valid = np.dot(o3_valid, W4) + b4\n",
    "    o4_valid = softmax(z4_valid)\n",
    "\n",
    "    valid_accuracy = np.sum(np.argmax(o4_valid, axis = 1) == y_valid)/ y_valid.shape[0]\n",
    "\n",
    "    if valid_accuracy > max_valid_accuracy:\n",
    "        max_valid_accuracy = valid_accuracy\n",
    "        epoch_opti = epoch\n",
    "\n",
    "        W4_opti = W4\n",
    "        b4_opti = b4\n",
    "        W3_opti = W3\n",
    "        b3_opti = b3\n",
    "        W2_opti  = W2\n",
    "        b2_opti = b2\n",
    "        W1_opti  = W1\n",
    "        b1_opti = b1\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Accuracy in validation set at epoch {epoch} is {valid_accuracy:.4f}\")\n",
    "\n",
    "print(f\"Highest Accuracy in validation set obtained at epoch {epoch_opti} is {max_valid_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOulDx8pDnnC"
   },
   "outputs": [],
   "source": [
    "#S·ª≠ d·ª•ng b·ªô Parameters t·ªët ƒë∆∞·ª£c ƒë√£ thu ƒë∆∞·ª£c sau khi train 10000 epochs\n",
    "#T√≠nh to√°n qu√° tr√¨nh forward v·ªõi input l√† b·ªô data train\n",
    "z1_train = np.dot(X_train, W1_opti) + b1_opti\n",
    "o1_train = relu(z1_train)\n",
    "\n",
    "z2_train = np.dot(o1_train, W2_opti) + b2_opti\n",
    "o2_train = relu(z2_train)\n",
    "\n",
    "z3_train = np.dot(o2_train, W3_opti) + b3_opti\n",
    "o3_train = softmax(z3_train)\n",
    "\n",
    "z4_train = np.dot(o3_train, W4_opti) + b4_opti\n",
    "o4_train = softmax(z4_train)\n",
    "\n",
    "#So s√°nh Label t·∫≠p train v√† K·∫øt qu·∫£ qu√° tr√¨nh forward tr√™n m·∫°ng Neuron \n",
    "np.sum(np.argmax(o4_train, axis = 1) == y_train)/ y_train.shape[0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab_08.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
